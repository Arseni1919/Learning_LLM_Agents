{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RAG with LlamaIndex",
   "id": "7c0b41c3e0ee1e6e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-16T11:13:55.320825Z",
     "start_time": "2025-05-16T11:13:55.313710Z"
    }
   },
   "source": [
    "import llama_index\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter  # from text to chunks\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding  # from chunks to vectors\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.huggingface_api import  HuggingFaceInferenceAPI\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.evaluation import  FaithfulnessEvaluator\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:13:57.262212Z",
     "start_time": "2025-05-16T11:13:57.258857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# GLOBALS\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "PHOENIX_API_KEY = os.getenv('PHOENIX_API_KEY')\n",
    "model_name = 'BAAI/bge-small-en-v1.5'\n",
    "big_model_name = 'Qwen/Qwen2.5-Coder-32B-Instruct'"
   ],
   "id": "9b8386f57fe6e407",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:13:57.692004Z",
     "start_time": "2025-05-16T11:13:57.485284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "llama_index.core.set_global_handler(\n",
    "    \"arize_phoenix\",\n",
    "    endpoint=\"https://llamatrace.com/v1/traces\"\n",
    ")"
   ],
   "id": "8f5c56ba6257248d",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:14:01.439186Z",
     "start_time": "2025-05-16T11:13:59.752035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reader = SimpleDirectoryReader(input_dir='papers')\n",
    "docs = reader.load_data()"
   ],
   "id": "8c2e151fa37711a7",
   "outputs": [],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:14:01.450666Z",
     "start_time": "2025-05-16T11:14:01.447892Z"
    }
   },
   "cell_type": "code",
   "source": "type(docs)",
   "id": "3d24761769b7d15f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:14:04.887663Z",
     "start_time": "2025-05-16T11:14:01.462022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_overlap=0),\n",
    "        HuggingFaceEmbedding(model_name=model_name)\n",
    "    ]\n",
    ")"
   ],
   "id": "4b13ddb203c1b737",
   "outputs": [],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:14:19.191566Z",
     "start_time": "2025-05-16T11:14:04.896078Z"
    }
   },
   "cell_type": "code",
   "source": "nodes = await pipeline.arun(documents=docs)",
   "id": "86202fe24b801d3e",
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:14:19.220193Z",
     "start_time": "2025-05-16T11:14:19.216398Z"
    }
   },
   "cell_type": "code",
   "source": "type(nodes)",
   "id": "d9b15f330ec92291",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:14:21.937848Z",
     "start_time": "2025-05-16T11:14:19.233585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = chromadb.PersistentClient(path='./alfred_chroma_db')\n",
    "chroma_collection = db.get_or_create_collection('alfred')\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_overlap=0),\n",
    "        HuggingFaceEmbedding(model_name=model_name)\n",
    "    ],\n",
    "    vector_store=vector_store\n",
    ")"
   ],
   "id": "7ce4edf4e6ffac15",
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:14:35.571840Z",
     "start_time": "2025-05-16T11:14:21.946393Z"
    }
   },
   "cell_type": "code",
   "source": "nodes = await pipeline.arun(documents=docs)",
   "id": "9b1bc8fa6eba409e",
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:14:51.877312Z",
     "start_time": "2025-05-16T11:14:35.591506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embed_model = HuggingFaceEmbedding(model_name=model_name)\n",
    "# index = VectorStoreIndex.from_vector_store(vector_store, embed_model=embed_model)\n",
    "index = VectorStoreIndex.from_documents(docs, embed_model=embed_model)"
   ],
   "id": "4180e4e41d109152",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:14:51.894054Z",
     "start_time": "2025-05-16T11:14:51.891539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# llm = HuggingFaceInferenceAPI(model_name=big_model_name, token=HF_TOKEN)\n",
    "# llm = Ollama(model=\"gemma3:1b\", request_timeout=120.0)\n",
    "# llm = Ollama(model=\"llama3.2:latest\", request_timeout=120.0)\n",
    "# llm = Ollama(model=\"qwen3:8b\", request_timeout=120.0)\n",
    "llm = Ollama(model=\"qwen3:1.7b\", request_timeout=120.0)"
   ],
   "id": "7c4e5e985ca207e6",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:15:06.188918Z",
     "start_time": "2025-05-16T11:14:51.904494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    response_mode=\"tree_summarize\",\n",
    "    # response_mode=\"compact\",\n",
    "    # response_mode=\"refine\",\n",
    ")\n",
    "answer = query_engine.query(\"What is CGA?\")\n",
    "print(answer)"
   ],
   "id": "24a1c17aa8ec0fea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking what CGA is. Let me look at the context provided.\n",
      "\n",
      "From the context, CGA is mentioned in the context of solving problems like SACG and LMAPF. There's a section about Theorem 1 and 2, which talk about the completeness and reachability of CGA. The algorithms CGA and CGA(L) are described, with CGA using a corridor selection method to guide agents towards their goals. The proof outlines mention that CGA ensures agents move optimally and evacuate corridors, leading to their goals. \n",
      "\n",
      "The user wants a concise answer without using the context directly. So, I need to summarize the key points: CGA is an algorithm that helps agents navigate grids to reach goals by selecting optimal paths and evacuating corridors, ensuring they can solve problems like SACG and LMAPF. It uses a corridor selection step and handles priorities for agents. The answer should avoid mentioning specific theorems and focus on the overall function and process.\n",
      "</think>\n",
      "\n",
      "CGA is an algorithm designed to solve complex navigation problems, such as SACG (Single-Agent Corridor Graph) and LMAPF (Multi-Agent Layout Map Problem Formulation). It ensures agents move optimally from their start positions to goals by selecting corridors that avoid obstacles. CGA operates by dynamically assigning priorities to agents and using a corridor selection process to guide them efficiently. The algorithm guarantees that agents can reach their goals in finite time, leveraging principles like corridor evacuation and path optimization. It combines strategic planning with real-time adjustments to handle both single and multi-agent scenarios.\n"
     ]
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:15:19.936299Z",
     "start_time": "2025-05-16T11:15:06.214140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# build index\n",
    "index = VectorStoreIndex.from_documents(docs, embed_model=embed_model)\n",
    "\n",
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=2,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\", llm=llm\n",
    ")\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")"
   ],
   "id": "df600c26886f635d",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:15:23.960367Z",
     "start_time": "2025-05-16T11:15:19.950479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# query\n",
    "response = query_engine.query(\"What is CGA stands for?\")\n",
    "print(response)"
   ],
   "id": "de2a745f6cb50d05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "</think>\n",
      "\n",
      "CGA stands for **Corridor Guidance Algorithm**. It is an algorithm designed to solve problems related to graph traversal and pathfinding, particularly in scenarios involving multiple agents and goals. The algorithm ensures that agents move optimally from one non-SV (non-solution vertex) to another, leveraging corridor selection to achieve efficient and guaranteed convergence to their goals.\n"
     ]
    }
   ],
   "execution_count": 167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:15:24.000448Z",
     "start_time": "2025-05-16T11:15:23.995547Z"
    }
   },
   "cell_type": "code",
   "source": "evaluator = FaithfulnessEvaluator(llm=llm)",
   "id": "f5b8a446fa59d04f",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:15:34.500086Z",
     "start_time": "2025-05-16T11:15:24.010269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eval_result = await evaluator.aevaluate_response(response=response)\n",
    "# print(eval_result)\n",
    "print(eval_result.passing)"
   ],
   "id": "9a9cbe1a3f43f833",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 169
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "b061881f18eb7e72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tools in LlamaIndex\n",
   "id": "14e70f0590da0027"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:32:05.357387Z",
     "start_time": "2025-05-16T11:32:05.352247Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8e81979461bf9abd",
   "outputs": [],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T11:15:34.539028Z",
     "start_time": "2025-05-16T11:15:34.537078Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fc3cf80ecb671e4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b189f65fe9974f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
